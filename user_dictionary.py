#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å –¥–ª—è LSwitch - UNIFIED VERSION
–ï–¥–∏–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å —Å —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏:
  weight > 0: –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞ = EN
  weight < 0: –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞ = RU
  weight = 0: —É–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å—å
"""

import json
import os
import time
from datetime import datetime


class UserDictionary:
    def __init__(self, dict_file=None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è
        
        Args:
            dict_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å–ª–æ–≤–∞—Ä—è
        """
        if dict_file is None:
            config_dir = os.path.expanduser('~/.config/lswitch')
            os.makedirs(config_dir, exist_ok=True)
            dict_file = os.path.join(config_dir, 'user_dict.json')
        
        self.dict_file = dict_file
        
        # –¢–∞–±–ª–∏—Ü–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ RU‚ÜîEN
        self.ru_to_en = str.maketrans(
            "–π—Ü—É–∫–µ–Ω–≥—à—â–∑—Ö—ä—Ñ—ã–≤–∞–ø—Ä–æ–ª–¥–∂—ç—è—á—Å–º–∏—Ç—å–±—é–ô–¶–£–ö–ï–ù–ì–®–©–ó–•–™–§–´–í–ê–ü–†–û–õ–î–ñ–≠–Ø–ß–°–ú–ò–¢–¨–ë–Æ",
            "qwertyuiop[]asdfghjkl;'zxcvbnm,.QWERTYUIOP{}ASDFGHJKL:\"ZXCVBNM<>"
        )
        self.en_to_ru = str.maketrans(
            "qwertyuiop[]asdfghjkl;'zxcvbnm,.QWERTYUIOP{}ASDFGHJKL:\"ZXCVBNM<>",
            "–π—Ü—É–∫–µ–Ω–≥—à—â–∑—Ö—ä—Ñ—ã–≤–∞–ø—Ä–æ–ª–¥–∂—ç—è—á—Å–º–∏—Ç—å–±—é–ô–¶–£–ö–ï–ù–ì–®–©–ó–•–™–§–´–í–ê–ü–†–û–õ–î–ñ–≠–Ø–ß–°–ú–ò–¢–¨–ë–Æ"
        )
        
        self.data = self._load()
        
        # –î–ª—è –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        self.last_save_time = time.time()
        self.save_interval = 3.0
        self.pending_save = False
    
    def _load(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –∏–∑ —Ñ–∞–π–ª–∞"""
        if os.path.exists(self.dict_file):
            try:
                with open(self.dict_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    # –ú–∏–≥—Ä–∞—Ü–∏—è —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
                    if 'protected' in data or ('conversions' in data and any(':' in k for k in data['conversions'].keys())):
                        print("üì¶ –ú–∏–≥—Ä–∞—Ü–∏—è —Å–ª–æ–≤–∞—Ä—è –Ω–∞ –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç...")
                        return self._migrate_old_format(data)
                    return data
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ user_dict: {e}")
        
        # –ù–æ–≤—ã–π –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
        return {
            'conversions': {},
            'settings': {
                'auto_convert_threshold': 5,
                'learning_step': 1,
                'correction_penalty': 1
            },
            'stats': {
                'total_conversions': 0,
                'total_corrections': 0
            }
        }
    
    def _migrate_old_format(self, old_data):
        """–ú–∏–≥—Ä–∞—Ü–∏—è —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞"""
        new_data = {
            'conversions': {},
            'settings': {
                'auto_convert_threshold': 5,
                'learning_step': 1,
                'correction_penalty': 1
            },
            'stats': {
                'total_conversions': 0,
                'total_corrections': 0
            }
        }
        
        migrated = 0
        
        # –ú–∏–≥—Ä–∞—Ü–∏—è conversions["word:en->ru"]
        if 'conversions' in old_data:
            for key, val in old_data['conversions'].items():
                if ':' not in key:
                    continue
                    
                parts = key.split(':')
                word = parts[0]
                direction = parts[1] if len(parts) > 1 else 'en->ru'
                
                if '->' in direction:
                    from_lang, to_lang = direction.split('->')
                    
                    # –ö–∞–Ω–æ–Ω–∏–∑–∏—Ä—É–µ–º –≤ EN
                    canonical = word.lower() if from_lang == 'en' else self._convert_text(word, 'ru', 'en').lower()
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–Ω–∞–∫ –≤–µ—Å–∞
                    old_weight = val.get('weight', 0)
                    if from_lang == 'en':
                        weight = old_weight  # –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π
                    else:
                        weight = -old_weight  # –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π
                    
                    if canonical not in new_data['conversions']:
                        new_data['conversions'][canonical] = {
                            'weight': weight,
                            'last_seen': val.get('last_seen', datetime.now().isoformat())
                        }
                        migrated += 1
                    else:
                        # –°—É–º–º–∏—Ä—É–µ–º –≤–µ—Å–∞
                        new_data['conversions'][canonical]['weight'] += weight
        
        print(f"‚úÖ –ú–∏–≥—Ä–∏—Ä–æ–≤–∞–Ω–æ {migrated} –∑–∞–ø–∏—Å–µ–π")
        return new_data
    
    def _save(self):
        """–û—Ç–ª–æ–∂–µ–Ω–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ"""
        current_time = time.time()
        
        if current_time - self.last_save_time >= self.save_interval:
            self._do_save()
            self.last_save_time = current_time
            self.pending_save = False
        else:
            self.pending_save = True
    
    def _do_save(self):
        """–†–µ–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª"""
        try:
            with open(self.dict_file, 'w', encoding='utf-8') as f:
                json.dump(self.data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è user_dict: {e}")
    
    def flush(self):
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ"""
        if self.pending_save:
            self._do_save()
            self.pending_save = False
    
    def _detect_lang(self, text):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —è–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É"""
        has_cyrillic = any(('–ê' <= c <= '–Ø') or ('–∞' <= c <= '—è') or c in '–Å—ë–™—ä–¨—å' for c in text)
        return 'ru' if has_cyrillic else 'en'
    
    def _convert_text(self, text, from_lang, to_lang):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –º–µ–∂–¥—É —Ä–∞—Å–∫–ª–∞–¥–∫–∞–º–∏"""
        if from_lang == to_lang:
            return text
        if from_lang == 'ru' and to_lang == 'en':
            return text.translate(self.ru_to_en)
        if from_lang == 'en' and to_lang == 'ru':
            return text.translate(self.en_to_ru)
        return text
    
    def _canonicalize(self, text, current_lang):
        """–ö–∞–Ω–æ–Ω–∏–∑–∞—Ü–∏—è: –≤—Å–µ–≥–¥–∞ EN –≤ lowercase"""
        if current_lang == 'en':
            return text.lower()
        return self._convert_text(text, 'ru', 'en').lower()
    
    # ========== –ü–£–ë–õ–ò–ß–ù–´–ï –ú–ï–¢–û–î–´ ==========
    
    def should_auto_convert(self, text, from_lang, to_lang, threshold=None):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω—É–∂–Ω–∞ –ª–∏ –∞–≤—Ç–æ–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            from_lang: –¢–µ–∫—É—â–∏–π —è–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞ ('ru' –∏–ª–∏ 'en')
            to_lang: –¶–µ–ª–µ–≤–æ–π —è–∑—ã–∫ (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –Ω–æ–≤–æ–π –ª–æ–≥–∏–∫–µ)
            threshold: –ü–æ—Ä–æ–≥ –∞–≤—Ç–æ–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ (–∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –µ—Å–ª–∏ None)
        
        Returns:
            bool: True –µ—Å–ª–∏ –Ω—É–∂–Ω–∞ –∞–≤—Ç–æ–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
        """
        if threshold is None:
            threshold = self.data['settings']['auto_convert_threshold']
        
        # –ö–∞–Ω–æ–Ω–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
        canonical = self._canonicalize(text, from_lang)
        
        if canonical not in self.data['conversions']:
            return False
        
        weight = self.data['conversions'][canonical]['weight']
        
        # –õ–æ–≥–∏–∫–∞ –∞–≤—Ç–æ–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏:
        # from_lang='ru', weight > 0 ‚Üí –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –µ—É—ã–µ‚Üítest
        # from_lang='en', weight < 0 ‚Üí –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å test‚Üí–µ—É—ã–µ
        if from_lang == 'ru' and weight >= threshold:
            return True
        if from_lang == 'en' and weight <= -threshold:
            return True
        
        return False
    
    def add_conversion(self, word, from_lang, to_lang, debug=False):
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç —É—Å–ø–µ—à–Ω—É—é —Ä—É—á–Ω—É—é –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é
        
        Args:
            word: –ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ (–î–û –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏)
            from_lang: –Ø–∑—ã–∫ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞
            to_lang: –¶–µ–ª–µ–≤–æ–π —è–∑—ã–∫
            debug: –í—ã–≤–æ–¥ –æ—Ç–ª–∞–¥–∫–∏
        """
        canonical = self._canonicalize(word, from_lang)
        learning_step = self.data['settings']['learning_step']
        
        if canonical not in self.data['conversions']:
            self.data['conversions'][canonical] = {
                'weight': 0,
                'last_seen': datetime.now().isoformat()
            }
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º/—É–º–µ–Ω—å—à–∞–µ–º –≤–µ—Å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        if from_lang == 'ru' and to_lang == 'en':
            # ru‚Üíen: —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å (—Å–¥–≤–∏–≥ –∫ EN)
            self.data['conversions'][canonical]['weight'] += learning_step
        elif from_lang == 'en' and to_lang == 'ru':
            # en‚Üíru: —É–º–µ–Ω—å—à–∞–µ–º –≤–µ—Å (—Å–¥–≤–∏–≥ –∫ RU)
            self.data['conversions'][canonical]['weight'] -= learning_step
        
        self.data['conversions'][canonical]['last_seen'] = datetime.now().isoformat()
        self.data['stats']['total_conversions'] += 1
        
        if debug:
            weight = self.data['conversions'][canonical]['weight']
            print(f"üìö Conversion: '{word}' ({from_lang}‚Üí{to_lang}) –≤–µ—Å ‚Üí {weight}")
        
        # –û—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ weight=0
        if self.data['conversions'][canonical]['weight'] == 0:
            del self.data['conversions'][canonical]
            if debug:
                print(f"üìö –£–¥–∞–ª–µ–Ω–æ: '{canonical}' (–≤–µ—Å = 0)")
        
        self._save()
    
    def add_correction(self, word, lang, debug=False):
        """
        –ö–æ—Ä—Ä–µ–∫—Ü–∏—è –∞–≤—Ç–æ–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ (–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–µ—Ä–Ω—É–ª –æ–±—Ä–∞—Ç–Ω–æ)
        
        Args:
            word: –ò–°–•–û–î–ù–û–ï —Å–ª–æ–≤–æ (–¥–æ –∞–≤—Ç–æ–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏)
            lang: –Ø–∑—ã–∫ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞
            debug: –û—Ç–ª–∞–¥–∫–∞
        """
        canonical = self._canonicalize(word, lang)
        penalty = self.data['settings']['correction_penalty']
        
        if canonical not in self.data['conversions']:
            # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –≤–µ—Å–æ–º
            self.data['conversions'][canonical] = {
                'weight': -penalty if lang == 'ru' else penalty,
                'last_seen': datetime.now().isoformat()
            }
        else:
            old_weight = self.data['conversions'][canonical]['weight']
            
            # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è: –¥–≤–∏–≥–∞–µ–º –≤–µ—Å –≤ –ü–†–û–¢–ò–í–û–ü–û–õ–û–ñ–ù–£–Æ —Å—Ç–æ—Ä–æ–Ω—É
            if lang == 'ru':
                # –ë—ã–ª–æ –∞–≤—Ç–æ–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –µ—É—ã–µ‚Üítest, –∏—Å–ø—Ä–∞–≤–∏–ª–∏ –æ–±—Ä–∞—Ç–Ω–æ
                # –£–º–µ–Ω—å—à–∞–µ–º –≤–µ—Å (—Å–¥–≤–∏–≥ –∫ RU)
                self.data['conversions'][canonical]['weight'] -= penalty
            else:
                # –ë—ã–ª–æ –∞–≤—Ç–æ–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ test‚Üí–µ—É—ã–µ, –∏—Å–ø—Ä–∞–≤–∏–ª–∏ –æ–±—Ä–∞—Ç–Ω–æ
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å (—Å–¥–≤–∏–≥ –∫ EN)
                self.data['conversions'][canonical]['weight'] += penalty
            
            new_weight = self.data['conversions'][canonical]['weight']
            
            if debug:
                print(f"üìö Correction: '{word}' ({lang}) –≤–µ—Å {old_weight} ‚Üí {new_weight}")
            
            # –£–¥–∞–ª—è–µ–º –µ—Å–ª–∏ –≤–µ—Å —Å—Ç–∞–ª 0
            if new_weight == 0:
                del self.data['conversions'][canonical]
                if debug:
                    print(f"üìö –£–¥–∞–ª–µ–Ω–æ: '{canonical}' (–≤–µ—Å = 0)")
        
        self.data['stats']['total_corrections'] += 1
        self._save()
    
    def get_conversion_weight(self, word, from_lang, to_lang):
        """
        –ü–æ–ª—É—á–∞–µ—Ç –≤–µ—Å –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
        
        Returns:
            int: –∞–±—Å–æ–ª—é—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–µ—Å–∞
        """
        canonical = self._canonicalize(word, from_lang)
        
        if canonical not in self.data['conversions']:
            return 0
        
        weight = self.data['conversions'][canonical]['weight']
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∞–±—Å–æ–ª—é—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ—Ä–æ–≥–∞
        if from_lang == 'ru':
            return weight if weight > 0 else 0
        else:
            return abs(weight) if weight < 0 else 0
    
    def is_protected(self, word, lang):
        """
        –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        –¢–µ–ø–µ—Ä—å –∑–∞—â–∏—Ç–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ –≤–µ—Å
        
        Returns:
            (False, 0): –≤—Å–µ–≥–¥–∞, –∑–∞—â–∏—Ç—ã –±–æ–ª—å—à–µ –Ω–µ—Ç
        """
        return (False, 0)
    
    def get_stats(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        return {
            'total_words': len(self.data['conversions']),
            'total_conversions': self.data['stats']['total_conversions'],
            'total_corrections': self.data['stats']['total_corrections'],
            'avg_weight': sum(abs(v['weight']) for v in self.data['conversions'].values()) / len(self.data['conversions']) if self.data['conversions'] else 0
        }
